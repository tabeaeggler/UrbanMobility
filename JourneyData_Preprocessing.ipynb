{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dcdf0d3",
   "metadata": {
    "id": "9dcdf0d3"
   },
   "source": [
    "# Fetch and Clean Journey Bike Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9dc53e",
   "metadata": {
    "id": "de9dc53e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import json\n",
    "import urllib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import datetime\n",
    "from rapidfuzz import fuzz\n",
    "from concurrent import futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcfc9d",
   "metadata": {
    "id": "fbfcfc9d"
   },
   "source": [
    "## 1. IMPORT BIKE JOURNEY DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c41fc5",
   "metadata": {},
   "source": [
    "### Fetch data\n",
    "Due to the dynamic loading of the data, web scraping is not possible. Therefore, the name of the files are copy & pased into a CSV file which then get fetched and combined with multiple API requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822bbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    \"\"\"\n",
    "    This function renames the columns in the provided dataframe 'df' as per the \n",
    "    mapping defined in 'column_names', and also changes the datatype of some columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # define a mapping of old column names to new standardized names\n",
    "    column_names = {\n",
    "        'End Station Id': 'EndStation Id',\n",
    "        'End station number': 'EndStation Id',\n",
    "        'Start Station Id': 'StartStation Id',\n",
    "        'Start station number': 'StartStation Id',\n",
    "        'End Station Name': 'EndStation Name',\n",
    "        'End station': 'EndStation Name',\n",
    "        'Start Station Name': 'StartStation Name',\n",
    "        'Start station': 'StartStation Name',\n",
    "        'Start date': 'Start Date',\n",
    "        'End Date': 'End Date',\n",
    "        'End date': 'End Date',\n",
    "        'Number': 'Rental Id',\n",
    "    }\n",
    "    \n",
    "    for old_name, new_name in column_names.items():\n",
    "            if old_name in df.columns:\n",
    "                df = df.rename(columns={old_name: new_name})\n",
    "                if new_name in ['EndStation Id', 'StartStation Id', 'Rental Id']:\n",
    "                    df[new_name] = pd.to_numeric(df[new_name], errors='coerce', downcast='integer')\n",
    "                elif new_name in ['Start Date', 'End Date']:\n",
    "                    df[new_name] = pd.to_datetime(df[new_name], infer_datetime_format=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3da34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the list of file names from a CSV file\n",
    "filenames = pd.read_csv('/Users/tabea/Documents/UrbanMobility/filenames-data.csv', header=None, squeeze=True)\n",
    "\n",
    "# combine a list of URL by add the base-url and filename\n",
    "base_url = 'http://cycling.data.tfl.gov.uk/usage-stats/'\n",
    "url_list = (base_url + urllib.parse.quote(x) for x in filenames)\n",
    "unused_cols = ['Total duration (ms)', 'Total duration', 'Duration', 'Duration_Seconds', 'Bike Id', 'Bike number', 'Bike model']\n",
    "\n",
    "# loop through each URL to extract data\n",
    "temp_dfs = []\n",
    "for url in url_list:\n",
    "    response = requests.get(url, verify=False, timeout=(3, 7))\n",
    "\n",
    "    if url.endswith('.csv'):\n",
    "        temp_df = pd.read_csv(io.StringIO(response.content.decode('utf-8')), usecols=lambda col: col not in unused_cols)\n",
    "\n",
    "    elif url.endswith('.xlsx'):\n",
    "        temp_df = pd.read_excel(io.BytesIO(response.content), usecols=lambda col: col not in unused_cols)\n",
    "\n",
    "    temp_df = rename_columns(temp_df)\n",
    "    temp_dfs.append(temp_df)\n",
    "\n",
    "# concatenate all temporary dataframes into a single dataframe\n",
    "merged_df = pd.concat(temp_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b301a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "71b301a1",
    "outputId": "14181a83-439e-4f78-a827-80c7613b6720"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84188068"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total amount of entries: 84'188'068\n",
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "287d0920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>EndStation Logical Terminal</th>\n",
       "      <th>endStationPriority_id</th>\n",
       "      <th>StartStation Logical Terminal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63097899.0</td>\n",
       "      <td>2017-03-15 00:06:00</td>\n",
       "      <td>631.0</td>\n",
       "      <td>Battersea Park Road, Nine Elms</td>\n",
       "      <td>2017-03-15 00:00:00</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Vauxhall Cross, Vauxhall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63097900.0</td>\n",
       "      <td>2017-03-15 00:05:00</td>\n",
       "      <td>397.0</td>\n",
       "      <td>Devonshire Terrace, Bayswater</td>\n",
       "      <td>2017-03-15 00:01:00</td>\n",
       "      <td>410.0</td>\n",
       "      <td>Edgware Road Station, Marylebone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>63097901.0</td>\n",
       "      <td>2017-03-15 00:06:00</td>\n",
       "      <td>426.0</td>\n",
       "      <td>Vincent Street, Pimlico</td>\n",
       "      <td>2017-03-15 00:01:00</td>\n",
       "      <td>177.0</td>\n",
       "      <td>Ashley Place, Victoria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>63097902.0</td>\n",
       "      <td>2017-03-15 00:12:00</td>\n",
       "      <td>462.0</td>\n",
       "      <td>Bonny Street, Camden Town</td>\n",
       "      <td>2017-03-15 00:01:00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Northington Street , Holborn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>63097903.0</td>\n",
       "      <td>2017-03-15 00:05:00</td>\n",
       "      <td>423.0</td>\n",
       "      <td>Eaton Square (South), Belgravia</td>\n",
       "      <td>2017-03-15 00:01:00</td>\n",
       "      <td>143.0</td>\n",
       "      <td>Pont Street, Knightsbridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   Rental Id             End Date  EndStation Id  \\\n",
       "0           0             0  63097899.0  2017-03-15 00:06:00          631.0   \n",
       "1           1             1  63097900.0  2017-03-15 00:05:00          397.0   \n",
       "2           2             2  63097901.0  2017-03-15 00:06:00          426.0   \n",
       "3           3             3  63097902.0  2017-03-15 00:12:00          462.0   \n",
       "4           4             4  63097903.0  2017-03-15 00:05:00          423.0   \n",
       "\n",
       "                   EndStation Name           Start Date  StartStation Id  \\\n",
       "0   Battersea Park Road, Nine Elms  2017-03-15 00:00:00             74.0   \n",
       "1    Devonshire Terrace, Bayswater  2017-03-15 00:01:00            410.0   \n",
       "2          Vincent Street, Pimlico  2017-03-15 00:01:00            177.0   \n",
       "3        Bonny Street, Camden Town  2017-03-15 00:01:00             22.0   \n",
       "4  Eaton Square (South), Belgravia  2017-03-15 00:01:00            143.0   \n",
       "\n",
       "                  StartStation Name  Unnamed: 9  Unnamed: 10  Unnamed: 11  \\\n",
       "0          Vauxhall Cross, Vauxhall         NaN          NaN          NaN   \n",
       "1  Edgware Road Station, Marylebone         NaN          NaN          NaN   \n",
       "2            Ashley Place, Victoria         NaN          NaN          NaN   \n",
       "3      Northington Street , Holborn         NaN          NaN          NaN   \n",
       "4        Pont Street, Knightsbridge         NaN          NaN          NaN   \n",
       "\n",
       "   EndStation Logical Terminal  endStationPriority_id  \\\n",
       "0                          NaN                    NaN   \n",
       "1                          NaN                    NaN   \n",
       "2                          NaN                    NaN   \n",
       "3                          NaN                    NaN   \n",
       "4                          NaN                    NaN   \n",
       "\n",
       "   StartStation Logical Terminal  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_raw.csv')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1edfad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from disk (if already fetched)\n",
    "# merged_df = pd.read_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36945983",
   "metadata": {
    "id": "36945983"
   },
   "source": [
    "## 2. CLEAN BIKE JOURNEY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "V4KsfJjNPnQ0",
   "metadata": {
    "id": "V4KsfJjNPnQ0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length before cleaning: 84188068\n"
     ]
    }
   ],
   "source": [
    "print(\"length before cleaning:\", len(merged_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d1764",
   "metadata": {},
   "source": [
    "### Drop columns starting with 'Unnamed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f838a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.filter(regex='^(?!Unnamed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef158ecc",
   "metadata": {},
   "source": [
    "### Drop rows with nan values only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "93a91139",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448dc25",
   "metadata": {},
   "source": [
    "### Investigate and drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a12007cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated rental ID samples count:  585398\n"
     ]
    }
   ],
   "source": [
    "# some files have same or overlapping content, but different names. \n",
    "# e.g: 01b Journey Data Extract 24Jan16-06Feb16.csv, 01bJourneyDataExtract24Jan16-06Feb16.csv\n",
    "    \n",
    "duplicates_rental_id = merged_df[merged_df['Rental Id'].duplicated(keep=False)]\n",
    "print(\"duplicated rental ID samples count: \", len(duplicates_rental_id))\n",
    "# duplicates_rental_id.to_csv('/Users/tabea/Documents/UrbanMobility/data/duplicates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "x2tK4QaAOqcw",
   "metadata": {
    "id": "x2tK4QaAOqcw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current length of df:  83895356\n"
     ]
    }
   ],
   "source": [
    "# drop all samples with duplicated rental id, sort first to keep the row with the most non-null values\n",
    "\n",
    "merged_df['nonnull_count'] = merged_df.notnull().sum(axis=1)\n",
    "merged_df = merged_df.sort_values(by=['Rental Id', 'nonnull_count'], ascending=[True, False])\n",
    "merged_df = merged_df.drop_duplicates(subset='Rental Id', keep='first')\n",
    "merged_df = merged_df.drop(columns='nonnull_count')\n",
    "\n",
    "print(\"current length of df: \", len(merged_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59cbec",
   "metadata": {},
   "source": [
    "### Investigate all nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7812b6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rental Id                               0\n",
      "End Date                           170358\n",
      "EndStation Id                      715522\n",
      "EndStation Name                    171824\n",
      "Start Date                              0\n",
      "StartStation Id                    234440\n",
      "StartStation Name                       0\n",
      "EndStation Logical Terminal      83665717\n",
      "endStationPriority_id            83665717\n",
      "StartStation Logical Terminal    83662856\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc28dfb3",
   "metadata": {},
   "source": [
    "### NaN values: StartStation Name & EndStation Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d46dc7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartStation Name NaNs count:  0\n",
      "EndStation Name NaNs: count   171824\n"
     ]
    }
   ],
   "source": [
    "StartStationName_NAN = merged_df[merged_df[\"StartStation Name\"].isna()]\n",
    "print(\"StartStation Name NaNs count: \", len(StartStationName_NAN))\n",
    "\n",
    "EndStationName_NAN = merged_df[merged_df[\"EndStation Name\"].isna()]\n",
    "print(\"EndStation Name NaNs: count  \", len(EndStationName_NAN))\n",
    "# EndStationName_NAN.to_csv('/Users/tabea/Documents/UrbanMobility/data/EndStationName_NAN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c931b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current df length: 83723532\n"
     ]
    }
   ],
   "source": [
    "# EndStation Name is only NaN if EndStation ID is also NaN -> they can't be mapped, so they must be removed.\n",
    "\n",
    "merged_df = merged_df.dropna(subset=['EndStation Id', 'EndStation Name'], how='all')\n",
    "print(\"current df length:\", len(merged_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72983817",
   "metadata": {},
   "source": [
    "### NaN values: Start Date and End Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bdb8ca9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date NaNs:  0\n",
      "End Date NaNs:  69\n"
     ]
    }
   ],
   "source": [
    "StartDate_NAN = merged_df[merged_df[\"Start Date\"].isna()]\n",
    "print(\"Start Date NaNs: \", len(StartDate_NAN))\n",
    "\n",
    "EndDate_NAN = merged_df[merged_df[\"End Date\"].isna()]\n",
    "print(\"End Date NaNs: \", len(EndDate_NAN))\n",
    "# EndDate_NAN.to_csv('/Users/tabea/Documents/UrbanMobility/data/EndDate_NAN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61495287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current df length: 83723463\n"
     ]
    }
   ],
   "source": [
    "# drop 69 entries with missing data\n",
    "\n",
    "merged_df = merged_df.dropna(subset=['End Date'])\n",
    "print(\"current df length:\", len(merged_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287e0725",
   "metadata": {},
   "source": [
    "### NaN values: StartStation Id & EndStation Id\n",
    "Numerous NaN values are observed in the 'StartStation Id' and 'EndStation Id' columns. The primary cause: cycling rides extending beyond a single calendar day. For these instances, stations are referred to as 'TerminalStation', each carrying a unique ID set with higher numbers (>852).\n",
    "\n",
    "Due to the mix of stationID and terminalID and lots of NaN values, the ID's get dropped and the name of the station is used as identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "38cd7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartStation Id NaNs count:  231579\n",
      "EndStation Id NaNs count:  543698\n"
     ]
    }
   ],
   "source": [
    "# StartStation Id: 234'440 NaN -> but most StartStation Names are known\n",
    "StartStationId_NAN = merged_df[merged_df[\"StartStation Id\"].isna()]\n",
    "print(\"StartStation Id NaNs count: \", len(StartStationId_NAN))\n",
    "# StartStationId_NAN.to_csv('/Users/tabea/Documents/UrbanMobility/data/StartStationId_NAN.csv')\n",
    "\n",
    "# EndStation Id: 715'522 NaN -> but most EndStation Names are known\n",
    "EndStationId_NAN = merged_df[merged_df[\"EndStation Id\"].isna()]\n",
    "print(\"EndStation Id NaNs count: \", len(EndStationId_NAN))\n",
    "# EndStationId_NAN.to_csv('/Users/tabea/Documents/UrbanMobility/data/EndStationId_NAN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ead5d81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of terminal station ID instaed of normal ID:  2788522\n"
     ]
    }
   ],
   "source": [
    "# only 852 station are present in the data. But there are also terminal station IDs that have higher values and are mixed in the data.\n",
    "# they can be found here: https://api.tfl.gov.uk/BikePoint/\n",
    "\n",
    "greater_than_852 = (merged_df['StartStation Id'] > 852) | (merged_df['EndStation Id'] > 852)\n",
    "print(\"count of terminal station ID instaed of normal ID: \", greater_than_852.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5eea5529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rental Id            0\n",
      "End Date             0\n",
      "EndStation Name      0\n",
      "Start Date           0\n",
      "StartStation Name    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# drop ID's\n",
    "\n",
    "merged_df = merged_df.drop(columns=['StartStation Id', 'EndStation Id', 'EndStation Logical Terminal', 'endStationPriority_id', 'StartStation Logical Terminal'])\n",
    "print(merged_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88156010",
   "metadata": {},
   "source": [
    "### Change dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5359c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"Rental Id\"] = merged_df[\"Rental Id\"].astype(int)\n",
    "merged_df[\"Start Date\"] = pd.to_datetime(merged_df[\"Start Date\"])\n",
    "merged_df[\"End Date\"] = pd.to_datetime(merged_df[\"End Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f4619",
   "metadata": {},
   "source": [
    "### Delete journeys from 2015 and 2023 (only start from April -> not complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ffd048",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['End Date'] = pd.to_datetime(merged_df['End Date'])\n",
    "mask_2015 = merged_df['End Date'].dt.year == 2015\n",
    "merged_df = merged_df[~mask_2015]\n",
    "\n",
    "merged_df['Start Date'] = pd.to_datetime(merged_df['Start Date'])\n",
    "mask_2015 = merged_df['Start Date'].dt.year == 2015\n",
    "merged_df = merged_df[~mask_2015]\n",
    "\n",
    "merged_df['End Date'] = pd.to_datetime(merged_df['End Date'])\n",
    "mask_2023 = merged_df['End Date'].dt.year == 2023\n",
    "merged_df = merged_df[~mask_2023]\n",
    "\n",
    "merged_df['Start Date'] = pd.to_datetime(merged_df['Start Date'])\n",
    "mask_2023 = merged_df['Start Date'].dt.year == 2023\n",
    "merged_df = merged_df[~mask_2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ed7e2b",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.rename(columns={\n",
    "    'Rental Id': 'rental_id',\n",
    "    'End Date': 'end_date',\n",
    "    'EndStation Name': 'endStation_name',\n",
    "    'Start Date': 'start_date',\n",
    "    'StartStation Name': 'startStation_name'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c94ed5",
   "metadata": {},
   "source": [
    "# 3. SAVE CLEANED DATA\n",
    "464'605 samples got deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9JSbvAxpPuIA",
   "metadata": {
    "id": "9JSbvAxpPuIA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length df after cleaning: 83723463\n"
     ]
    }
   ],
   "source": [
    "print(\"length df after cleaning:\", len(merged_df))\n",
    "# merged_df.to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "history_visible": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
