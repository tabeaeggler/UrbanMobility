{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dcdf0d3",
   "metadata": {
    "id": "9dcdf0d3"
   },
   "source": [
    "# 1. JOURNEY DATA\n",
    "link: https://cycling.data.tfl.gov.uk"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3502d197",
   "metadata": {
    "id": "3502d197"
   },
   "source": [
    "# March 2020 to December 2021\n",
    "# covid restrictions uk timeline: https://www.instituteforgovernment.org.uk/sites/default/files/2022-12/timeline-coronavirus-lockdown-december-2021.pdf\n",
    "\n",
    "# https://codeigo.com/python/fix-requests-max-retries-exceeded-with-url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9dc53e",
   "metadata": {
    "id": "de9dc53e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import urllib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcfc9d",
   "metadata": {
    "id": "fbfcfc9d"
   },
   "source": [
    "## a. import journey cycle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3da34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to rename columns\n",
    "\n",
    "def rename_columns(df):\n",
    "    column_names = {\n",
    "        'End Station Id': 'EndStation Id',\n",
    "        'End station number': 'EndStation Id',\n",
    "        'Start Station Id': 'StartStation Id',\n",
    "        'Start station number': 'StartStation Id',\n",
    "        'End Station Name': 'EndStation Name',\n",
    "        'End station': 'EndStation Name',\n",
    "        'Start Station Name': 'StartStation Name',\n",
    "        'Start station': 'StartStation Name',\n",
    "        'Start date': 'Start Date',\n",
    "        'End Date': 'End Date',\n",
    "        'End date': 'End Date',\n",
    "        'Number': 'Rental Id',\n",
    "    }\n",
    "    \n",
    "    for old_name, new_name in column_names.items():\n",
    "            if old_name in df.columns:\n",
    "                df = df.rename(columns={old_name: new_name})\n",
    "                if new_name in ['EndStation Id', 'StartStation Id', 'Rental Id']:\n",
    "                    df[new_name] = pd.to_numeric(df[new_name], errors='coerce', downcast='integer')\n",
    "                elif new_name in ['Start Date', 'End Date']:\n",
    "                    df[new_name] = pd.to_datetime(df[new_name], infer_datetime_format=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# read the list of file names\n",
    "filenames = pd.read_csv('/Users/tabea/Documents/UrbanMobility/filenames-data.csv', header=None, squeeze=True)\n",
    "\n",
    "# combine base-url and filenames\n",
    "base_url = 'http://cycling.data.tfl.gov.uk/usage-stats/'\n",
    "url_list = (base_url + urllib.parse.quote(x) for x in filenames)\n",
    "unused_cols = ['Total duration (ms)', 'Total duration', 'Duration', 'Duration_Seconds', 'Bike Id', 'Bike number', 'Bike model']\n",
    "\n",
    "# loop over the urls and extract the data\n",
    "temp_dfs = []\n",
    "for url in url_list:\n",
    "    response = requests.get(url, verify=False, timeout=(3, 7))\n",
    "\n",
    "    if url.endswith('.csv'):\n",
    "        temp_df = pd.read_csv(io.StringIO(response.content.decode('utf-8')), usecols=lambda col: col not in unused_cols)\n",
    "\n",
    "    elif url.endswith('.xlsx'):\n",
    "        temp_df = pd.read_excel(io.BytesIO(response.content), usecols=lambda col: col not in unused_cols)\n",
    "\n",
    "    temp_df = rename_columns(temp_df)\n",
    "    temp_dfs.append(temp_df)\n",
    "\n",
    "# concatenate the new data to the existing data\n",
    "merged_df = pd.concat(temp_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b301a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "71b301a1",
    "outputId": "14181a83-439e-4f78-a827-80c7613b6720"
   },
   "outputs": [],
   "source": [
    "# total amount of entries: 84'188'068\n",
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292tJkGISg90",
   "metadata": {
    "id": "292tJkGISg90"
   },
   "outputs": [],
   "source": [
    "merged_df.to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E7ZBURStI3If",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "E7ZBURStI3If",
    "outputId": "25ef51df-c17f-4997-a4a3-9d50934ae916"
   },
   "outputs": [],
   "source": [
    "merged_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36945983",
   "metadata": {
    "id": "36945983"
   },
   "source": [
    "## b. clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V4KsfJjNPnQ0",
   "metadata": {
    "id": "V4KsfJjNPnQ0"
   },
   "outputs": [],
   "source": [
    "print(\"length before cleaning:\", len(merged_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59cbec",
   "metadata": {},
   "source": [
    "### investigation nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ff70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rental: no nan, only different header namings\n",
    "\n",
    "nan_rows_rental = merged_df[merged_df[\"Rental Id\"].isna()]\n",
    "print(\"count rental nans: \", len(nan_rows_rental))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e258d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start date & start station id & start station name: no nan, only different namings\n",
    "\n",
    "nan_rows_start = merged_df.loc[(merged_df[\"StartStation Name\"].isna()) | (merged_df[\"StartStation Id\"].isna()) | (merged_df[\"Start Date\"].isna())] \n",
    "print(\"count start nans: \", len(nan_rows_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b90847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end date & end station id & end station name: 4536 nan\n",
    "# example: id:63097949, bike-id:1628, start-date:15.03.17 00:13, start-station-id:274, start-station-name: Warwick Road, Olympia\n",
    "\n",
    "nan_rows_end = merged_df.loc[(merged_df[\"EndStation Name\"].isna()) | (merged_df[\"EndStation Id\"].isna()) | (merged_df[\"End Date\"].isna())] \n",
    "print(nan_rows_end.head())\n",
    "print(\"count: \", len(nan_rows_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448dc25",
   "metadata": {},
   "source": [
    "### investigate duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12007cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some files are read twice. e.g: 01b Journey Data Extract 24Jan16-06Feb16.csv, 01bJourneyDataExtract24Jan16-06Feb16.csv\n",
    "\n",
    "duplicates = merged_df[merged_df.duplicated(keep=False)]\n",
    "print(len(duplicates))\n",
    "duplicates.to_csv('/Users/tabea/Documents/UrbanMobility/data/duplicates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate duplicates by date: 14 dates in 2016 with duplicates\n",
    "\n",
    "duplicates[\"Start Date\"] = pd.to_datetime(duplicates[\"Start Date\"])\n",
    "print(duplicates[\"Start Date\"].dt.date.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546638f1",
   "metadata": {},
   "source": [
    "### drop nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29881a11",
   "metadata": {
    "id": "29881a11"
   },
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "\n",
    "merged_df.dropna(axis=0, subset=[\"EndStation Id\", \"End Date\", \"EndStation Name\"], inplace=True)\n",
    "print(merged_df.shape)\n",
    "print(merged_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf2682",
   "metadata": {},
   "source": [
    "### drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x2tK4QaAOqcw",
   "metadata": {
    "id": "x2tK4QaAOqcw"
   },
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea53656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicated rental Id: none found\n",
    "\n",
    "duplicates_rental_id = merged_df[merged_df['Rental Id'].duplicated(keep=False)]\n",
    "print(len(duplicates_rental_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c9c1d5",
   "metadata": {},
   "source": [
    "### drop unused cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ocFZy-aN9CE",
   "metadata": {
    "id": "3ocFZy-aN9CE"
   },
   "outputs": [],
   "source": [
    "merged_df.drop(merged_df.iloc[:,7:], axis=1, inplace=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88156010",
   "metadata": {},
   "source": [
    "### change dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5359c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.dtypes)\n",
    "\n",
    "merged_df[\"EndStation Id\"] = merged_df[\"EndStation Id\"].astype(int)\n",
    "merged_df[\"Rental Id\"] = merged_df[\"Rental Id\"].astype(int)\n",
    "merged_df[\"Start Date\"] = pd.to_datetime(merged_df[\"Start Date\"])\n",
    "\n",
    "print(merged_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9JSbvAxpPuIA",
   "metadata": {
    "id": "9JSbvAxpPuIA"
   },
   "outputs": [],
   "source": [
    "print(\"length after cleaning:\", len(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dkiff5nKwxs",
   "metadata": {
    "id": "3dkiff5nKwxs"
   },
   "source": [
    "## c. split data by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kz7QSqUJLAQ-",
   "metadata": {
    "id": "kz7QSqUJLAQ-"
   },
   "outputs": [],
   "source": [
    "# Split merged_df by year\n",
    "groups = merged_df.groupby(pd.Grouper(key='Start Date', freq='Y'))\n",
    "\n",
    "# Create a new DataFrame for each year\n",
    "yearly_dfs = {}\n",
    "for year, group in groups:\n",
    "    yearly_dfs[year.year] = group.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae7aa2",
   "metadata": {
    "id": "e0ae7aa2"
   },
   "outputs": [],
   "source": [
    "# plot length of all dataframes\n",
    "\n",
    "length_of_dfs = [len(yearly_dfs[2015]), len(yearly_dfs[2016]), len(yearly_dfs[2017]), len(yearly_dfs[2018]), len(yearly_dfs[2019]), len(yearly_dfs[2020]), len(yearly_dfs[2021]), len(yearly_dfs[2022])]\n",
    "years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Blues\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.barplot(x=years, y=length_of_dfs, ax=ax, color=\"royalblue\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Total Entries\")\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{int(x):,}'))\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + p.get_width()/2., p.get_height(), f\"{int(p.get_height())}\", \n",
    "            fontsize=12, color='black', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e4231",
   "metadata": {
    "id": "0b8e4231"
   },
   "source": [
    "### save data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc51b3",
   "metadata": {
    "id": "afcc51b3"
   },
   "outputs": [],
   "source": [
    "yearly_dfs[2015].to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_2015.csv')\n",
    "yearly_dfs[2016].to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_2016.csv')\n",
    "yearly_dfs[2017].to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_2017.csv')\n",
    "yearly_dfs[2018].to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_2018.csv')\n",
    "yearly_dfs[2019].to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_2019.csv')\n",
    "yearly_dfs[2020].to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_2020.csv')\n",
    "yearly_dfs[2021].to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_2021.csv')\n",
    "yearly_dfs[2022].to_csv('/Users/tabea/Documents/UrbanMobility/data/journey_data_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d28abc8",
   "metadata": {
    "id": "dbf93785"
   },
   "source": [
    "# 2. BIKE STATION LOCATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcabe405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "base = \"https://tfl.gov.uk/tfl/syndication/feeds/cycle-hire/livecyclehireupdates.xml\"\n",
    "response = requests.get(base)\n",
    "root = ET.fromstring(response.content)\n",
    "\n",
    "data = []\n",
    "for station in root:\n",
    "    station_data = {\n",
    "        \"id\": int(station[0].text),\n",
    "        \"name\": station[1].text,\n",
    "        \"lat\": float(station[3].text),\n",
    "        \"lon\": float(station[4].text),\n",
    "        \"capacity\": int(station[12].text)\n",
    "    }\n",
    "    data.append(station_data)\n",
    "\n",
    "bike_locs = pd.DataFrame(data)\n",
    "\n",
    "bike_locs.to_csv('/Users/tabea/Documents/UrbanMobility/data/bike_locations.csv', header=True, index=None)\n",
    "\n",
    "print(bike_locs.shape)\n",
    "bike_locs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b6b51",
   "metadata": {},
   "source": [
    "### visualize the bike locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e20ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# create a map centered on London\n",
    "london_coords = (51.5074, -0.1278)\n",
    "m = folium.Map(location=london_coords, zoom_start=12, tiles='Stamen Toner')\n",
    "\n",
    "# add markers for each bike station location\n",
    "for index, row in bike_locs.iterrows():\n",
    "    popup_text = f\"{row['name']} (capacity: {row['capacity']})\"\n",
    "    marker = folium.Marker(location=(row['lat'], row['lon']), popup=popup_text)\n",
    "    marker.add_to(m)\n",
    "\n",
    "# add a heatmap layer\n",
    "heat_data = [[row['lat'], row['lon']] for index, row in bike_locs.iterrows()]\n",
    "heatmap = folium.FeatureGroup(heat_data)\n",
    "heatmap.add_to(m)\n",
    "\n",
    "# save the map as an HTML file\n",
    "m.save('map_bike_loc.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c775a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame('map_bike_loc.html', width=900, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f9ad",
   "metadata": {},
   "source": [
    "# 3. ADD LONDON BOROUGH DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276cad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get london borough data"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "history_visible": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
