{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170f4557",
   "metadata": {},
   "source": [
    "# Web scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fa97c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ad398",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://cycling.data.tfl.gov.uk/usage-stats/161JourneyDataExtract08May2019-14May2019.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fe5dab",
   "metadata": {},
   "source": [
    "## get cycling tfl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37624995",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7k/528cxkys5vv34d3vcx99jrwh0000gn/T/ipykernel_78796/1045846865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mwebsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://cycling.data.tfl.gov.uk/usage-stats/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0murl_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwebsite\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_list' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "## Read list of names of all files from a separate CSV - can't scrape them from website as they're hidden\n",
    "with open('urls_bike.csv', 'r') as f:\n",
    "    csv_list = f.read().splitlines()\n",
    "\n",
    "## Downloading all of the bike journey CSV files and appending to one dataset\n",
    "website = 'http://cycling.data.tfl.gov.uk/usage-stats/'\n",
    "\n",
    "url_list = [website + urllib.parse.quote(x) for x in csv_list]\n",
    "dfs = (pd.read_csv(url) for url in url_list)\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(all_data.shape)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88e219cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/528cxkys5vv34d3vcx99jrwh0000gn/T/ipykernel_78796/1424749855.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path, options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"0a040fa1f7ccb6a2699aaa2b01fb1ec4\", element=\"eecdcabe-a157-40d3-be88-6fb7f40be3b1\")>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'WebElement' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7k/528cxkys5vv34d3vcx99jrwh0000gn/T/ipykernel_78796/1424749855.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Scrape the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"DataExtract\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WebElement' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "# Set up the Chrome driver\n",
    "chrome_driver_path = \"/Users/tabea/Documents/UrbanMobility/chromedriver\" \n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path, options=options)\n",
    "\n",
    "# Navigate to the page\n",
    "url = \"https://cycling.data.tfl.gov.uk/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the table to load\n",
    "wait = WebDriverWait(driver, 10)\n",
    "table = wait.until(EC.presence_of_element_located((By.ID, \"tbody-content\")))\n",
    "\n",
    "# Scrape the table\n",
    "for row in table.find_all(\"tr\"):\n",
    "    link = row.find(\"a\")\n",
    "    if link and \"DataExtract\" in link.text:\n",
    "        file_url = link.get(\"href\")\n",
    "        filename = os.path.basename(file_url)\n",
    "        filepath = os.path.join(\"data\", \"cycling-data-tfl\", filename)\n",
    "        urllib.request.urlretrieve(file_url, filepath)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca749f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/528cxkys5vv34d3vcx99jrwh0000gn/T/ipykernel_78796/1103566991.py:16: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://cycling.data.tfl.gov.uk/\"\n",
    "urlFiles = \"https://cycling.data.tfl.gov.uk/usage-stats\"\n",
    "search_string = \"DataExtract22\"\n",
    "download_directory = \"data/cycling-data-tfl\"\n",
    "\n",
    "# Create the download directory if it doesn't exist\n",
    "os.makedirs(download_directory, exist_ok=True)\n",
    "\n",
    "# Use Selenium to simulate a browser and get the dynamically generated content\n",
    "chrome_driver_path = \"/Users/tabea/Documents/UrbanMobility/chromedriver\" \n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get(url)\n",
    "html_content = driver.page_source\n",
    "driver.quit()\n",
    "\n",
    "# Use BeautifulSoup to parse the HTML content\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Find the tbody element that contains the links\n",
    "tbody = soup.find(\"tbody\", id=\"tbody-content\")\n",
    "\n",
    "# Find all links in the tbody element that contain the search string\n",
    "links = tbody.find_all(\"a\", href=lambda href: href and search_string in href)\n",
    "\n",
    "# Download each CSV file\n",
    "for link in links:\n",
    "    # Get the URL of the CSV file\n",
    "    file_url = url + link.get(\"href\")\n",
    "    \n",
    "    # Send a request to the CSV file and save it to disk\n",
    "    file_path = os.path.join(download_directory, link.text)\n",
    "    response = requests.get(file_url)\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "        print(f\"{link.text} downloaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efaa93e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tbody id=\"tbody-content\">\n",
      "</tbody>\n"
     ]
    }
   ],
   "source": [
    "print(tbody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8eeca46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a504da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
